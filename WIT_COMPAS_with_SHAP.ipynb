{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WIT COMPAS with SHAP",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Id_0GukgNv",
        "colab_type": "text"
      },
      "source": [
        "## What-If Tool and SHAP on COMPAS keras model\n",
        "\n",
        "This notebook shows:\n",
        "- Training of a keras model on the [COMPAS](https://www.kaggle.com/danofer/compass) dataset.\n",
        "- Use of What-If Tool on the trained model.\n",
        "- Explanation of inference results using [SHAP](https://github.com/slundberg/shap).\n",
        "- Use of What-If Tool to display SHAP values.\n",
        "\n",
        "Copyright 2019 Google LLC.\n",
        "SPDX-License-Identifier: Apache-2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1HvYDrvor2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Install What-If Tool Widget and SHAP library\n",
        "!pip install --upgrade --quiet witwidget shap"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzEwkr3SoyLh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Read training dataset from CSV {display-mode: \"form\"}\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import witwidget\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBx6BTumpb1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Filter out entries with no indication of recidivism or no compass score\n",
        "df = df[df['is_recid'] != -1]\n",
        "df = df[df['decile_score'] != -1]\n",
        "\n",
        "# Rename recidivism column\n",
        "df['recidivism_within_2_years'] = df['is_recid']\n",
        "\n",
        "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
        "df['COMPASS_determination'] = np.where(df['score_text'] == 'Low', 0, 1)\n",
        "\n",
        "df = pd.get_dummies(df, columns=['sex', 'race'])\n",
        "\n",
        "# Get list of all columns from the dataset we will use for model input or output.\n",
        "input_features = ['sex_Female', 'sex_Male', 'age', 'race_African-American', 'race_Caucasian', 'race_Hispanic', 'race_Native American', 'race_Other', 'priors_count', 'juv_fel_count', 'juv_misd_count', 'juv_other_count']\n",
        "\n",
        "to_keep = input_features + ['recidivism_within_2_years', 'COMPASS_determination']\n",
        "\n",
        "to_remove = [col for col in df.columns if col not in to_keep]\n",
        "df = df.drop(columns=to_remove)\n",
        "\n",
        "input_columns = df.columns.tolist()\n",
        "labels = df['COMPASS_determination']\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T0-uRsdsI-N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_for_training = df.drop(columns=['COMPASS_determination', 'recidivism_within_2_years'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0ZfePT1rTmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_size = int(len(df_for_training) * 0.8)\n",
        "train_data = df_for_training[:train_size]\n",
        "train_labels = labels[:train_size]\n",
        "\n",
        "test_data = df_for_training[train_size:]\n",
        "test_labels = labels[train_size:]\n",
        "\n",
        "test_data_with_labels = df[train_size:]\n",
        "\n",
        "# This is the size of the array we'll be feeding into our model for each example\n",
        "input_size = len(train_data.iloc[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T2XThgosWX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(200, input_shape=(input_size,), activation='relu'))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(25, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwDe1MhUsaI1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjgNhSCDsayt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(train_data.values, train_labels.values, epochs=4, batch_size=32, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-VAPm8O6kdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Helper methods to convert examples to/from tf.Example and vector for model prediction.\n",
        "def df_to_tf_examples(df):\n",
        "  examples = []\n",
        "  columns = df.columns.values.tolist()\n",
        "  for index, row in df.iterrows():\n",
        "      example = tf.train.Example()\n",
        "      for col in columns:\n",
        "          if col.startswith('sex_') and row[col] == 1:\n",
        "            example.features.feature[col[:3]].bytes_list.value.append(col[4:].encode('utf-8'))\n",
        "          elif col.startswith('race_') and row[col] == 1:\n",
        "            example.features.feature[col[:4]].bytes_list.value.append(col[5:].encode('utf-8'))\n",
        "          elif df[col].dtype is np.dtype(np.int64):\n",
        "              example.features.feature[col].int64_list.value.append(int(row[col]))\n",
        "          elif df[col].dtype is np.dtype(np.float64):\n",
        "              example.features.feature[col].float_list.value.append(row[col])\n",
        "      examples.append(example)\n",
        "  return examples\n",
        "\n",
        "def from_tf_example(example):\n",
        "  inp = []\n",
        "  for i, col in enumerate(input_columns):\n",
        "    if col == 'recidivism_within_2_years' or col == 'COMPASS_determination':\n",
        "       continue\n",
        "    if col.startswith('sex'):\n",
        "      if example.features.feature[col[:3]].bytes_list.value and example.features.feature[col[:3]].bytes_list.value[0].decode() == col[4:]:\n",
        "        inp.append(1)\n",
        "      else:\n",
        "        inp.append(0)\n",
        "    elif col.startswith('race'):\n",
        "      if example.features.feature[col[:4]].bytes_list.value and example.features.feature[col[:4]].bytes_list.value[0].decode() == col[5:]:\n",
        "        inp.append(1)\n",
        "      else:\n",
        "        inp.append(0)\n",
        "    else:\n",
        "      inp.append(example.features.feature[col].int64_list.value[0])\n",
        "  return inp\n",
        "\n",
        "# For using WIT to display SHAP values, we send each vector entry to WIT as its\n",
        "# own feature, as opposed to collapsing categorical features into a single\n",
        "# string for display in the tool. This is because each vector entry for the\n",
        "# one-hot encodings for the categorical features has its own SHAP value to\n",
        "# display.\n",
        "def df_to_shap_tf_examples(df):\n",
        "  examples = []\n",
        "  columns = df.columns.values.tolist()\n",
        "  for index, row in df.iterrows():\n",
        "      example = tf.train.Example()\n",
        "      for col in columns:\n",
        "          example.features.feature[col].int64_list.value.append(int(row[col]))\n",
        "      examples.append(example)\n",
        "  return examples\n",
        "\n",
        "def from_shap_tf_example(example):\n",
        "  inp = []\n",
        "  for i, col in enumerate(input_columns):\n",
        "    if col == 'recidivism_within_2_years' or col == 'COMPASS_determination':\n",
        "       continue\n",
        "    inp.append(example.features.feature[col].int64_list.value[0])\n",
        "      \n",
        "  return inp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3SwrGJBNZZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert data to tf.Example format for use in WIT\n",
        "examples_for_wit = df_to_tf_examples(test_data_with_labels)\n",
        "examples_for_shap_wit = df_to_shap_tf_examples(test_data_with_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HN6d87fJ62Xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Show model results in WIT\n",
        "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder\n",
        "num_datapoints = 1000  #@param {type: \"number\"}\n",
        "\n",
        "def custom_predict(examples_to_infer):\n",
        "  model_inputs = [from_tf_example(ex) for ex in examples_to_infer]\n",
        "  preds = model.predict([model_inputs])\n",
        "  return [[1 - pred[0], pred[0]] for pred in preds]\n",
        "\n",
        "config_builder = WitConfigBuilder(examples_for_wit[:num_datapoints]).set_custom_predict_fn(\n",
        "  custom_predict).set_target_feature('recidivism_within_2_years')\n",
        "\n",
        "ww = WitWidget(config_builder, height=800)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lI18CwYiQotq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shap\n",
        "\n",
        "# Create an explainer by passing a subset of our training data\n",
        "explainer = shap.DeepExplainer(model, train_data.values[:200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iywHwbJJkeYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Explain predictions of the model on the first 5 examples from our test set\n",
        "shap_values = explainer.shap_values(test_data.values[:5])\n",
        "shap_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KF00pJvkeicT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#@title Show model results and SHAP values in WIT\n",
        "from witwidget.notebook.visualization import WitWidget, WitConfigBuilder\n",
        "num_datapoints = 1000  #@param {type: \"number\"}\n",
        "\n",
        "# Return model predictions and SHAP values for each inference.\n",
        "def custom_predict_with_shap(examples_to_infer):\n",
        "  model_inputs = [from_shap_tf_example(ex) for ex in examples_to_infer]\n",
        "  preds = model.predict([model_inputs])\n",
        "  preds = [[1 - pred[0], pred[0]] for pred in preds]\n",
        "\n",
        "  shap_output = explainer.shap_values(np.array(model_inputs))[0]\n",
        "  attributions = []\n",
        "  for shap in shap_output:\n",
        "    attrs = {}\n",
        "    for i, col in enumerate(df_for_training.columns):\n",
        "      attrs[col] = shap[i]\n",
        "    attributions.append(attrs)\n",
        "  ret = {'predictions': preds, 'attributions': attributions}\n",
        "  return ret\n",
        "\n",
        "config_builder = WitConfigBuilder(examples_for_shap_wit[:num_datapoints]).set_custom_predict_fn(\n",
        "  custom_predict_with_shap).set_target_feature('recidivism_within_2_years')\n",
        "\n",
        "ww = WitWidget(config_builder, height=800)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}